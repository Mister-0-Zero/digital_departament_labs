{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b699e1d",
   "metadata": {},
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599954e2",
   "metadata": {},
   "source": [
    "## –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∏ –∑–∞–ø–∏—Å—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nfrom urllib.request import urlretrieve\\nimport zipfile\\n\\n# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ data, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\\nos.makedirs(\\'./data\\', exist_ok=True)\\n\\n# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º\\ntrain_zip_path = \\'./data/train.zip\\'\\nvalid_zip_path = \\'./data/valid.zip\\'\\n\\n# –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–æ–≤\\nurlretrieve(\\'https://www.dropbox.com/scl/fi/bel6gt6vsb3onahlxvyjc/train_fix.zip?rlkey=q2wscp6wv9j2hbk07y1mbcm54&dl=1\\', train_zip_path)\\nurlretrieve(\\'https://www.dropbox.com/scl/fi/cwwblwhvqgwubb8a4xg90/valid.zip?rlkey=mow899lvyawq4wku2m8lfvrh3&dl=1\\', valid_zip_path)\\n\\n# –†–∞—Å–ø–∞–∫–æ–≤–∫–∞\\nwith zipfile.ZipFile(train_zip_path, \\'r\\') as zip_ref:\\n    zip_ref.extractall(\\'./data/train\\')\\n\\nwith zipfile.ZipFile(valid_zip_path, \\'r\\') as zip_ref:\\n    zip_ref.extractall(\\'./data/valid\\')\\n\\nprint(\"–ì–æ—Ç–æ–≤–æ! –ê—Ä—Ö–∏–≤—ã —Å–∫–∞—á–∞–Ω—ã –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω—ã –≤ –ø–∞–ø–∫—É ./data\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ data, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º\n",
    "train_zip_path = './data/train.zip'\n",
    "valid_zip_path = './data/valid.zip'\n",
    "\n",
    "# –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–æ–≤\n",
    "urlretrieve('https://www.dropbox.com/scl/fi/bel6gt6vsb3onahlxvyjc/train_fix.zip?rlkey=q2wscp6wv9j2hbk07y1mbcm54&dl=1', train_zip_path)\n",
    "urlretrieve('https://www.dropbox.com/scl/fi/cwwblwhvqgwubb8a4xg90/valid.zip?rlkey=mow899lvyawq4wku2m8lfvrh3&dl=1', valid_zip_path)\n",
    "\n",
    "# –†–∞—Å–ø–∞–∫–æ–≤–∫–∞\n",
    "with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/train')\n",
    "\n",
    "with zipfile.ZipFile(valid_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/valid')\n",
    "\n",
    "print(\"–ê—Ä—Ö–∏–≤—ã —Å–∫–∞—á–∞–Ω—ã –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω—ã –≤ –ø–∞–ø–∫—É ./data\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff33c1",
   "metadata": {},
   "source": [
    "## –†–∞–∑–¥–µ–ª–∏–º –≤–∏–¥—ã –±–∞–±–æ—á–µ–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º –≤ —Ä–∞–∑–Ω—ã–µ –ø–∞–ø–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af727ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport shutil\\nfrom pathlib import Path\\n\\ndef restructure_dataset(source_dir):\\n    for file_name in os.listdir(source_dir):\\n        if not file_name.endswith((\\'.jpg\\', \\'.jpeg\\', \\'.png\\')):\\n            continue\\n\\n        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –∫–ª–∞—Å—Å–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–¥–æ –ø–µ—Ä–≤–æ–π —Å–∫–æ–±–∫–∏)\\n        class_name = file_name.split(\\' (\\')[0]\\n        class_dir = os.path.join(source_dir, class_name)\\n\\n        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\\n        os.makedirs(class_dir, exist_ok=True)\\n\\n        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É\\n        src_path = os.path.join(source_dir, file_name)\\n        dst_path = os.path.join(class_dir, file_name)\\n        shutil.move(src_path, dst_path)\\n\\n# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ train –∏ valid\\nrestructure_dataset(\\'./data/train\\')\\nrestructure_dataset(\\'./data/valid\\')\\n\\nprint(\"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def restructure_dataset(source_dir):\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        if not file_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –∫–ª–∞—Å—Å–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–¥–æ –ø–µ—Ä–≤–æ–π —Å–∫–æ–±–∫–∏)\n",
    "        class_name = file_name.split(' (')[0]\n",
    "        class_dir = os.path.join(source_dir, class_name)\n",
    "\n",
    "        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É\n",
    "        src_path = os.path.join(source_dir, file_name)\n",
    "        dst_path = os.path.join(class_dir, file_name)\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ train –∏ valid\n",
    "restructure_dataset('./data/train')\n",
    "restructure_dataset('./data/valid')\n",
    "\n",
    "print(\"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d8a98",
   "metadata": {},
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8604f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de5aca",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–∫–ª—é—á–∏–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ —á–∏—Å–ª–æ –ø–æ—Ç–æ–∫–æ–≤ (80% –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0de91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "max_threads = int(os.cpu_count() * 0.8)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(max_threads)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(max_threads)\n",
    "torch.set_num_threads(max_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988a92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0755ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "train_data_full = datasets.ImageFolder(root='./data/train', transform=transform_train)\n",
    "valid_data = datasets.ImageFolder(root='./data/valid', transform=transform_valid)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –≤–∞–ª–∏–¥–∞—Ü–∏—é\n",
    "train_size = int(0.8 * len(train_data_full))\n",
    "val_size = len(train_data_full) - train_size\n",
    "train_data, train_val_data = random_split(train_data_full, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db4851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader'—ã\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(train_val_data, batch_size=32)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc7ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤: 75\n"
     ]
    }
   ],
   "source": [
    "# –ß–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤\n",
    "num_classes = len(train_data_full.classes)\n",
    "print(f\"–í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a429d9",
   "metadata": {},
   "source": [
    "# –†–∞–±–æ—Ç–∞ —Å –º–æ–¥–µ–ª—å—é"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610f4fc",
   "metadata": {},
   "source": [
    "## –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b0dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfddc7b",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dc15a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 941.220, Train Accuracy: 4.60%\n",
      "üéØ Validation Accuracy: 8.19%\n",
      "‚úÖ Model improved and saved.\n",
      "Epoch 2/10, Loss: 857.656, Train Accuracy: 8.24%\n",
      "üéØ Validation Accuracy: 12.44%\n",
      "‚úÖ Model improved and saved.\n",
      "Epoch 3/10, Loss: 806.498, Train Accuracy: 11.74%\n",
      "üéØ Validation Accuracy: 14.43%\n",
      "‚úÖ Model improved and saved.\n",
      "Epoch 4/10, Loss: 766.699, Train Accuracy: 14.94%\n",
      "üéØ Validation Accuracy: 18.96%\n",
      "‚úÖ Model improved and saved.\n",
      "Epoch 5/10, Loss: 741.114, Train Accuracy: 16.40%\n",
      "üéØ Validation Accuracy: 19.87%\n",
      "‚úÖ Model improved and saved.\n",
      "Epoch 6/10, Loss: 720.603, Train Accuracy: 18.34%\n",
      "üéØ Validation Accuracy: 21.76%\n",
      "‚úÖ Model improved and saved.\n",
      "Epoch 7/10, Loss: 699.797, Train Accuracy: 20.18%\n",
      "üéØ Validation Accuracy: 21.70%\n",
      "üîÅ No improvement. Patience: 1/5\n",
      "Epoch 8/10, Loss: 688.235, Train Accuracy: 21.81%\n",
      "üéØ Validation Accuracy: 24.56%\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     17\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:484\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1131\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.3f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    # Step for LR scheduler\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), './best_model.pth')\n",
    "        print(\"Model improved and saved.\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement. Patience: {counter}/{patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51be649",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': 6,  # –Ω–æ–º–µ—Ä –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–π —ç–ø–æ—Ö–∏\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict() if 'scheduler' in locals() else None,\n",
    "}, './checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoint.pth'\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if checkpoint['scheduler_state_dict'] is not None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1  # –Ω–∞—á–∏–Ω–∞–µ–º —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —ç–ø–æ—Ö–∏\n",
    "    print(f\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å —ç–ø–æ—Ö–∏ {start_epoch}\")\n",
    "else:\n",
    "    print(\"Checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω. –û–±—É—á–µ–Ω–∏–µ –Ω–∞—á–Ω—ë—Ç—Å—è —Å –Ω—É–ª—è.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa241c",
   "metadata": {},
   "source": [
    "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51da184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './model/butterfly_model_better.pth')\n",
    "print(\"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975ca97",
   "metadata": {},
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a895a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Accuracy –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ: 68.40%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in valid_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"üéØ Accuracy –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
