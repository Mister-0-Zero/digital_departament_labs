{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b699e1d",
   "metadata": {},
   "source": [
    "# Загрузка и обработка файлов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599954e2",
   "metadata": {},
   "source": [
    "## Скачивание данных, распаковка и запись"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b104978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nfrom urllib.request import urlretrieve\\nimport zipfile\\n\\n# Создание папки data, если не существует\\nos.makedirs(\\'./data\\', exist_ok=True)\\n\\n# Пути к файлам\\ntrain_zip_path = \\'./data/train.zip\\'\\nvalid_zip_path = \\'./data/valid.zip\\'\\n\\n# Скачивание архивов\\nurlretrieve(\\'https://www.dropbox.com/scl/fi/bel6gt6vsb3onahlxvyjc/train_fix.zip?rlkey=q2wscp6wv9j2hbk07y1mbcm54&dl=1\\', train_zip_path)\\nurlretrieve(\\'https://www.dropbox.com/scl/fi/cwwblwhvqgwubb8a4xg90/valid.zip?rlkey=mow899lvyawq4wku2m8lfvrh3&dl=1\\', valid_zip_path)\\n\\n# Распаковка\\nwith zipfile.ZipFile(train_zip_path, \\'r\\') as zip_ref:\\n    zip_ref.extractall(\\'./data/train\\')\\n\\nwith zipfile.ZipFile(valid_zip_path, \\'r\\') as zip_ref:\\n    zip_ref.extractall(\\'./data/valid\\')\\n\\nprint(\"Готово! Архивы скачаны и распакованы в папку ./data\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "# Создание папки data, если не существует\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "# Пути к файлам\n",
    "train_zip_path = './data/train.zip'\n",
    "valid_zip_path = './data/valid.zip'\n",
    "\n",
    "# Скачивание архивов\n",
    "urlretrieve('https://www.dropbox.com/scl/fi/bel6gt6vsb3onahlxvyjc/train_fix.zip?rlkey=q2wscp6wv9j2hbk07y1mbcm54&dl=1', train_zip_path)\n",
    "urlretrieve('https://www.dropbox.com/scl/fi/cwwblwhvqgwubb8a4xg90/valid.zip?rlkey=mow899lvyawq4wku2m8lfvrh3&dl=1', valid_zip_path)\n",
    "\n",
    "# Распаковка\n",
    "with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/train')\n",
    "\n",
    "with zipfile.ZipFile(valid_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/valid')\n",
    "\n",
    "print(\"Готово! Архивы скачаны и распакованы в папку ./data\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff33c1",
   "metadata": {},
   "source": [
    "## Разделим виды бабочек по классам в разные папки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af727ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport shutil\\nfrom pathlib import Path\\n\\ndef restructure_dataset(source_dir):\\n    for file_name in os.listdir(source_dir):\\n        if not file_name.endswith((\\'.jpg\\', \\'.jpeg\\', \\'.png\\')):\\n            continue\\n\\n        # Извлекаем имя класса из имени файла (до первой скобки)\\n        class_name = file_name.split(\\' (\\')[0]\\n        class_dir = os.path.join(source_dir, class_name)\\n\\n        # Создаем папку, если нужно\\n        os.makedirs(class_dir, exist_ok=True)\\n\\n        # Перемещаем файл в папку\\n        src_path = os.path.join(source_dir, file_name)\\n        dst_path = os.path.join(class_dir, file_name)\\n        shutil.move(src_path, dst_path)\\n\\n# Применяем к train и valid\\nrestructure_dataset(\\'./data/train\\')\\nrestructure_dataset(\\'./data/valid\\')\\n\\nprint(\"✅ Структура папок исправлена\")\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def restructure_dataset(source_dir):\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        if not file_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        # Извлекаем имя класса из имени файла (до первой скобки)\n",
    "        class_name = file_name.split(' (')[0]\n",
    "        class_dir = os.path.join(source_dir, class_name)\n",
    "\n",
    "        # Создаем папку, если нужно\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # Перемещаем файл в папку\n",
    "        src_path = os.path.join(source_dir, file_name)\n",
    "        dst_path = os.path.join(class_dir, file_name)\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "# Применяем к train и valid\n",
    "restructure_dataset('./data/train')\n",
    "restructure_dataset('./data/valid')\n",
    "\n",
    "print(\"✅ Структура папок исправлена\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d8a98",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8604f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc0de91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "988a92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аугментации и нормализация\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0755ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета\n",
    "train_data_full = datasets.ImageFolder(root='./data/train', transform=transform_train)\n",
    "valid_data = datasets.ImageFolder(root='./data/valid', transform=transform_valid)\n",
    "\n",
    "# Разделение тренировочной на обучающую и внутреннюю валидацию\n",
    "train_size = int(0.8 * len(train_data_full))\n",
    "val_size = len(train_data_full) - train_size\n",
    "train_data, train_val_data = random_split(train_data_full, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8db4851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader'ы\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(train_val_data, batch_size=32)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dc7ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего классов: 75\n"
     ]
    }
   ],
   "source": [
    "# Число классов\n",
    "num_classes = len(train_data_full.classes)\n",
    "print(f\"Всего классов: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a429d9",
   "metadata": {},
   "source": [
    "# Работа с моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610f4fc",
   "metadata": {},
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45b0dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ButterflyCNNImproved(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ButterflyCNNImproved, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 14 * 14, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfddc7b",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8dc15a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Loss: 851.550, Accuracy: 11.35%\n",
      "Epoch 2/7, Loss: 610.435, Accuracy: 31.11%\n",
      "Epoch 3/7, Loss: 487.324, Accuracy: 43.59%\n",
      "Epoch 4/7, Loss: 405.291, Accuracy: 52.21%\n",
      "Epoch 5/7, Loss: 350.717, Accuracy: 58.56%\n",
      "Epoch 6/7, Loss: 310.785, Accuracy: 61.81%\n",
      "Epoch 7/7, Loss: 269.968, Accuracy: 66.80%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ButterflyCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Тренировка\n",
    "epochs = 7\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.3f}, Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dd0a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DO-обучение] Epoch 8, Loss: 83.824, Accuracy: 88.99%\n",
      "[DO-обучение] Epoch 9, Loss: 78.072, Accuracy: 89.55%\n",
      "[DO-обучение] Epoch 10, Loss: 78.554, Accuracy: 89.45%\n"
     ]
    }
   ],
   "source": [
    "additional_epochs = 3\n",
    "for epoch in range(epochs, epochs + additional_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"[DO-обучение] Epoch {epoch+1}, Loss: {running_loss:.3f}, Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa241c",
   "metadata": {},
   "source": [
    "## Сохранение и загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e51da184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './model/butterfly_model_new.pth')\n",
    "print(\"Модель сохранена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975ca97",
   "metadata": {},
   "source": [
    "# Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a895a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Accuracy на валидационном наборе: 68.40%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in valid_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"🎯 Accuracy на валидационном наборе: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
